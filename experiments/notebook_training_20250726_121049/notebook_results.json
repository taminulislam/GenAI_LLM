{
  "train_loss": 3.467724548339844,
  "train_steps": 5000,
  "epochs_trained": 2,
  "output_dir": "..\\experiments\\notebook_training_20250726_121049",
  "final_model_path": "..\\experiments\\notebook_training_20250726_121049\\final_model",
  "dataset_size": 20000,
  "model_name": "microsoft/DialoGPT-small",
  "train_runtime": 3148.2518,
  "train_samples_per_second": 12.705,
  "train_steps_per_second": 1.588,
  "total_flos": 4408809744513024.0
}